{\rtf1\ansi\ansicpg1252\cocoartf2513
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fswiss\fcharset0 Helvetica-Oblique;\f2\fnil\fcharset0 HelveticaNeue;
}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww22360\viewh12460\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs28 \cf0 TransWorld Data Analysis - Bash, SQL and Python Code
\fs24 \
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\fs28 \cf0 \ul \ulc0 Bash code\ulnone \
\
File name for the raw data: transworld_data.csv\
\
-
\f1\i Used the sed function to make separations between columns clearer.\
Since the space between date and time needed to be replaced by a\
semi-colon, the space between the words \'91North\'92/\'91South\'92 and America needed\
to be replaced with an underscore (i.e., North America \'97> North_America).\
This is so that a semi-colon doesn\'92t get placed between them by mistake.
\f0\i0 \
\
sed  's/North America/North_America/g' transworld_data.csv > dda.csv\
sed 's/South America/South_America/g' dda.csv > ddb.csv\
sed 's/ /;/g' ddb.csv > ddc.csv\
rm dda.csv | rm ddb.csv\
mv ddc.csv transworld_data_properformat.csv\
\
-
\f1\i Separated raw data into sections according to category\
first (first visits), return (returning visits-for reading), subscribe (subscribers), purchase (purchases)
\f0\i0 \
\
-
\f1\i Kept only rows with SEO, AdWords and Reddit from the entire data set to create a new file for only first visits to the website
\f0\i0 \
grep 'SEO\\|AdWords\\|Reddit' transworld_data_properformat.csv > first_visit.csv\
\
-
\f1\i Took rows that are \'91read\'92 only and put them into a new file
\f0\i0 \
grep read transworld_data_properformat.csv >  read_only.csv\
\
-
\f1\i Kept only rows that do not contain \'91SEO\'92, \'91AdWords\'92 and \'91Reddit\'92 from \'91read only\'92 and created a new file for returning visits/reading sessions
\f0\i0 \
grep -v 'SEO\\|AdWords\\|Reddit' read_only.csv > return.csv\
\

\f1\i -Kept only rows that contain \'91subscribe\'92 to create a new file for subscribers
\f0\i0 \
grep subscribe transworld_data_properformat.csv > subscribe.csv\
 \

\f1\i -Kept only rows that contain \'91buy\'92 to create a new file for purchases
\f0\i0 \
grep buy transworld_data_properformat.csv > purchase.csv\
\
\
-
\f1\i Placed data into SQL, created SQL tables for each portion of the dataset
\f0\i0 \
\
\pard\pardeftab560\slleading20\partightenfactor0

\f2 \cf0 psql -U datafolder -d postgres
\f0 \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \
CREATE TABLE first_visit (\
the_date DATE,\
the_time TIME,\
event_type TEXT,\
country TEXT,\
user_id BIGINT,\
source TEXT,\
topic TEXT);\
\
CREATE TABLE return_visits (\
the_date DATE,\
the_time TIME,\
event_type TEXT,\
country TEXT,\
user_id BIGINT,\
topic TEXT);\
\
CREATE TABLE subscribe (\
the_date DATE,\
the_time TIME,\
event_type TEXT,\
user_id BIGINT);\
\
CREATE TABLE purchase (\
the_date DATE,\
the_time TIME,\
event_type TEXT,\
user_id BIGINT,\
price INTEGER);\
\
-Placed data into the SQL tables\
\
\pard\pardeftab560\slleading20\partightenfactor0

\f2 \cf0 COPY first_visit FROM '/home/datafolder/testtasktables/testtask/first.csv' DELIMITER ';';\
COPY return_visits FROM '/home/datafolder/testtasktables/testtask/return.csv' DELIMITER ';';\
COPY subscribe FROM '/home/datafolder/testtasktables/testtask/subscribe.csv' DELIMITER ';';\
COPY purchase FROM '/home/datafolder/testtasktables/testtask/purchase.csv' DELIMITER ';';
\f0 \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \
}